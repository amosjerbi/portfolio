name: Fetch Instagram Posts and Deploy to GitHub Pages

on:
  push:
    branches:
      - main
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  fetch-instagram:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil

      - name: Fetch Instagram Posts
        env:
          INSTAGRAM_ACCESS_TOKEN: ${{ secrets.INSTAGRAM_ACCESS_TOKEN }}
        run: |
          python3 - << EOF
          import os
          import json
          import requests
          from datetime import datetime
          from dateutil.parser import parse

          def fetch_instagram_posts(access_token, max_posts=120):
              base_url = "https://graph.instagram.com/me/media"
              fields = "id,caption,media_type,media_url,permalink,timestamp"
              
              all_posts = []
              next_url = f"{base_url}?fields={fields}&access_token={access_token}&limit=50"
              
              while next_url and len(all_posts) < max_posts:
                  try:
                      response = requests.get(next_url)
                      data = response.json()
                      
                      # Detailed error logging
                      if 'error' in data:
                          print(f"Instagram API Error: {data['error']}")
                          break
                      
                      # Filter and process posts
                      for post in data.get('data', []):
                          # Skip videos and keep only images and carousel albums
                          if post['media_type'] not in ['IMAGE', 'CAROUSEL_ALBUM']:
                              continue
                          
                          # Parse timestamp and convert to ISO format
                          try:
                              timestamp = parse(post['timestamp']).isoformat()
                          except Exception:
                              timestamp = post['timestamp']
                          
                          # Truncate caption if too long
                          caption = post.get('caption', '')
                          if len(caption) > 500:
                              caption = caption[:500] + '...'
                          
                          processed_post = {
                              'id': post['id'],
                              'caption': caption,
                              'media_type': post['media_type'],
                              'media_url': post['media_url'],
                              'permalink': post['permalink'],
                              'timestamp': timestamp
                          }
                          
                          all_posts.append(processed_post)
                      
                      # Get next page URL
                      next_url = data.get('paging', {}).get('next')
                  
                  except Exception as e:
                      print(f"Error fetching posts: {e}")
                      break
              
              return all_posts

          # Fetch posts
          access_token = os.environ['INSTAGRAM_ACCESS_TOKEN']
          posts = fetch_instagram_posts(access_token)
          
          # Sort posts by timestamp, most recent first
          posts.sort(key=lambda x: x['timestamp'], reverse=True)
          
          # Prepare output
          output = {
              'data': posts,
              'metadata': {
                  'total_posts': len(posts),
                  'fetched_at': datetime.utcnow().isoformat()
              }
          }
          
          # Ensure data directory exists
          os.makedirs('assets/data', exist_ok=True)
          
          # Write to JSON file with explicit error handling
          try:
              with open('assets/data/instagram-posts.json', 'w', encoding='utf-8') as f:
                  json.dump(output, f, ensure_ascii=False, indent=2)
              print(f"Successfully saved {len(posts)} Instagram posts")
          except Exception as e:
              print(f"Error writing JSON file: {e}")
          
          # Additional logging
          print("Current working directory:", os.getcwd())
          print("Contents of assets/data:", os.listdir('assets/data') if os.path.exists('assets/data') else "Directory not found")
          EOF

      - name: Debug File Creation
        run: |
          ls -l assets/data
          cat assets/data/instagram-posts.json || echo "File not found"

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add assets/data/instagram-posts.json
          git commit -m "Update Instagram posts via GitHub Actions" || echo "No changes to commit"
          git push

  deploy:
    needs: fetch-instagram
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: Setup Pages
        uses: actions/configure-pages@v3
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v2
        with:
          path: '.'
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2
